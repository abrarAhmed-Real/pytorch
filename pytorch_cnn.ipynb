{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RwCIjv6zpCRB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=datasets.MNIST(root='./data',train=True,download=True)"
      ],
      "metadata": {
        "id": "JaJ6kLiIpv3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d1a5e5-8634-43c1-9ebf-ccb7075cc2b5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 16102789.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 435284.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 4147264.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 11891715.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=data.data"
      ],
      "metadata": {
        "id": "3jlefqXnp72q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape,type(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdH5EtBzqEeU",
        "outputId": "23723152-8b19-40cd-e864-44f3e9723ff1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 28, 28]), torch.Tensor)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=data.targets"
      ],
      "metadata": {
        "id": "e438ZqUGqL87"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape,type(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIRlldQ2qPCc",
        "outputId": "b1f86ae4-441f-4ecc-ed99-eec942ed6f85"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000]), torch.Tensor)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "o1XpkV5aqQWh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Converts the image to a PyTorch tensor and scales it to [0, 1]\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensor\n",
        "])\n"
      ],
      "metadata": {
        "id": "B8mt-OIEqtI8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rQbV1rFdsPEq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape,X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Itt4sBYhrVss",
        "outputId": "938a72c0-b1a8-45e1-8faf-4f0657c59fd3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([48000, 28, 28]), torch.Size([12000, 28, 28]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,X,y,transforms=None):\n",
        "        self.X=X\n",
        "        self.y=y\n",
        "        self.transforms=transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        data=self.X[idx][None,...].float()/255\n",
        "        label=self.y[idx]\n",
        "\n",
        "        if self.transforms:\n",
        "            data=self.transforms(data)\n",
        "\n",
        "        return data,label"
      ],
      "metadata": {
        "id": "dQMbBsQ_qzVw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2erPaZs3sNgm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=torch.utils.data.DataLoader(CustomDataset(X_train,y_train),batch_size=32,shuffle=True)\n",
        "test_loader=torch.utils.data.DataLoader(CustomDataset(X_test,y_test),batch_size=32,shuffle=False)"
      ],
      "metadata": {
        "id": "oWNfIXicq7JQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkeUoEF1rEhA",
        "outputId": "401538bd-9dc4-430f-d743-a0fec9ddd82a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              " \n",
              " \n",
              "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              " \n",
              " \n",
              "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              " \n",
              " \n",
              "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              " \n",
              " \n",
              "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]]]]),\n",
              " tensor([6, 7, 4, 1, 3, 3, 6, 0, 4, 0, 7, 5, 0, 4, 5, 6, 1, 7, 3, 1, 2, 1, 0, 8,\n",
              "         1, 1, 6, 9, 7, 5, 0, 6])]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyModel,self).__init__()\n",
        "    self.conv1=torch.nn.Conv2d(1,32,kernel_size=3,stride=1,padding=1)\n",
        "    self.conv2=torch.nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1)\n",
        "    self.pool=torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "    self.fc1=torch.nn.Linear(64*7*7,128)\n",
        "    self.fc2=torch.nn.Linear(128,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.conv1(x)\n",
        "    x=torch.nn.functional.relu(x)\n",
        "    x=self.pool(x)\n",
        "    x=self.conv2(x)\n",
        "    x=torch.nn.functional.relu(x)\n",
        "    x=self.pool(x)\n",
        "    x=torch.flatten(x,1)\n",
        "    x=self.fc1(x)\n",
        "    x=torch.nn.functional.relu(x)\n",
        "    x=self.fc2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Yxfxx2o8rHD5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=MyModel()\n",
        "model(torch.rand(1,1,28,28)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJXU1qcrusmb",
        "outputId": "aa73146a-3957-4cfa-af52-c892719b820d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model(torch.rand(1,28,28)).view(1,-1).shape"
      ],
      "metadata": {
        "id": "hYteImb8uwy2"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,train_loader,val_loader,optimizer,criterion,num_epochs):\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    total_train_loss=0\n",
        "    total_val_loss=0\n",
        "    for batch_idx,(data,target) in enumerate(train_loader):\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "      output=model(data)\n",
        "      loss=criterion(output,target)\n",
        "      total_train_loss+=loss.item()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    with torch.no_grad():\n",
        "      for batch_idx,(data,target) in enumerate(val_loader):\n",
        "        model.eval()\n",
        "        output=model(data)\n",
        "        val_loss=criterion(output,target)\n",
        "        total_val_loss+=val_loss.item()\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {total_train_loss/len(data):.4f}, Val Loss: {total_val_loss/len(data):.4f}')"
      ],
      "metadata": {
        "id": "uzyIDdFevDIg"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion=torch.nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "train(model,train_loader,test_loader,optimizer,criterion,num_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1onydfavE-a",
        "outputId": "441cce84-d7fd-417a-ccd9-60620c4e578b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 2.4718, Val Loss: 0.5762\n",
            "Epoch 2/10, Train Loss: 1.5583, Val Loss: 0.5184\n",
            "Epoch 3/10, Train Loss: 1.1267, Val Loss: 0.4170\n",
            "Epoch 4/10, Train Loss: 0.7884, Val Loss: 0.4651\n",
            "Epoch 5/10, Train Loss: 0.6870, Val Loss: 0.5202\n",
            "Epoch 6/10, Train Loss: 0.5282, Val Loss: 0.5035\n",
            "Epoch 7/10, Train Loss: 0.4505, Val Loss: 0.5869\n",
            "Epoch 8/10, Train Loss: 0.2631, Val Loss: 0.5803\n",
            "Epoch 9/10, Train Loss: 0.3997, Val Loss: 0.6288\n",
            "Epoch 10/10, Train Loss: 0.2522, Val Loss: 0.6375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Tyas4iuMyCSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QKt-N6cAyYhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QXyoT5HmyaQW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}